{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FBPost</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drug Runners and  a U.S. Senator have somethin...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heres a single, to add, to Kindle. Just read t...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              FBPost Label\n",
       "0  Drug Runners and  a U.S. Senator have somethin...     O\n",
       "1  Heres a single, to add, to Kindle. Just read t...     O\n",
       "2  If you tire of Non-Fiction.. Check out http://...     O\n",
       "3    Ghost of Round Island is supposedly nonfiction.     O\n",
       "4  Why is Barnes and Nobles version of the Kindle...     N"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"fb_sentiment.csv\")\n",
    "data.drop(data.columns[0], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading precomputed word2vec\n",
    "\n",
    "(I am using https://nlp.stanford.edu/data/glove.6B.zip word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:04, 98629.50it/s] \n",
      "400000it [00:06, 59025.18it/s]\n",
      "400000it [00:13, 30356.33it/s]\n",
      "400000it [00:19, 20254.96it/s]\n"
     ]
    }
   ],
   "source": [
    "dim_to_word2vec_dict = {}\n",
    "\n",
    "dims_lst = [50, 100, 200, 300]\n",
    "for d in dims_lst:\n",
    "    word2vec = {}\n",
    "    with open(f\"glove.6B/glove.6B.{d}d.txt\") as file:\n",
    "        for line in tqdm(file):\n",
    "            lst = line.split()\n",
    "            word = lst[0].lower()\n",
    "            vec = np.array(lst[1:], dtype=np.float64)\n",
    "            word2vec[word] = vec\n",
    "    dim_to_word2vec_dict[d] = word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting messages into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(data[\"Label\"].apply(dict(zip(np.unique(data[\"Label\"]), [[1, 0, 0], [0, 1, 0], [0, 0, 1]])).get)))\n",
    "dim_to_X_dict = {}\n",
    "for d in dims_lst:\n",
    "    def text_to_vec(text):\n",
    "        word2vec = dim_to_word2vec_dict[d]\n",
    "        keys = word2vec.keys()\n",
    "        vec_lst = [word2vec[word.lower()] if word in keys else np.array([np.nan] * d) for word in text.split()]\n",
    "        return np.array(np.zeros(d)) if np.all(np.isnan(vec_lst)) else np.nanmean(vec_lst, axis=0)\n",
    "    \n",
    "    dim_to_X_dict[d] = np.array(list(data[\"FBPost\"].apply(text_to_vec)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the train, validation, test split (0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ind_train, ind_test = train_test_split(np.arange(data.shape[0]), test_size=0.2)\n",
    "ind_train, ind_valid = train_test_split(ind_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating hyperparameters\n",
    "\n",
    "Trying to variate layer sizes, activation functions and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "fst_layer_size_lst = [64, 128, 256, 512]\n",
    "snd_layer_size_lst = [16, 32, 64]\n",
    "hidden_activation_function_lst = output_activation_function_lst = [\"relu\", \"sigmoid\", \"softmax\"]\n",
    "batch_size_lst = [16, 32, 64]\n",
    "\n",
    "parameters_lst = list(product(dims_lst,\n",
    "                              fst_layer_size_lst,\n",
    "                              snd_layer_size_lst,\n",
    "                              hidden_activation_function_lst,\n",
    "                              output_activation_function_lst,\n",
    "                              batch_size_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using AUC metric as a standard most popular (I believe) metric for classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1296/1296 [48:46<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "results = {\"word2vec_dim\": [],\n",
    "           \"fst_layer_size\": [],\n",
    "           \"snd_layer_size\": [],\n",
    "           \"hidden_activation_function\": [],\n",
    "           \"output_activation_functions\": [],\n",
    "           \"batch_size\": [],\n",
    "           \"AUC\": [],\n",
    "          }\n",
    "\n",
    "for params in tqdm(parameters_lst):\n",
    "    dim, fst_layer_size, snd_layer_size, hidden_activation_function, output_activation_function, batch_size = params\n",
    "    X = dim_to_X_dict[dim]\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(fst_layer_size, activation=hidden_activation_function, input_shape=(dim,)))\n",
    "    model.add(layers.Dense(snd_layer_size, activation=hidden_activation_function))\n",
    "    model.add(layers.Dense(3, activation=output_activation_function))\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=[\"AUC\"])\n",
    "    model.fit(X[ind_train], y[ind_train], \n",
    "              epochs=20, \n",
    "              batch_size=batch_size,\n",
    "              validation_data=(X[ind_valid], y[ind_valid]),\n",
    "              verbose=0)\n",
    "    \n",
    "    for key, param in zip(results.keys(), params):\n",
    "        results[key].append(param)\n",
    "    \n",
    "    _, valid_AUC = model.evaluate(X[ind_valid], y[ind_valid], verbose=0)\n",
    "    results[\"AUC\"].append(valid_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word2vec_dim</th>\n",
       "      <th>fst_layer_size</th>\n",
       "      <th>snd_layer_size</th>\n",
       "      <th>hidden_activation_function</th>\n",
       "      <th>output_activation_functions</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>16</td>\n",
       "      <td>0.864237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>16</td>\n",
       "      <td>0.863706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>32</td>\n",
       "      <td>0.862844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>32</td>\n",
       "      <td>0.862162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>100</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>softmax</td>\n",
       "      <td>64</td>\n",
       "      <td>0.860906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word2vec_dim  fst_layer_size  snd_layer_size hidden_activation_function  \\\n",
       "519           100             256              32                       relu   \n",
       "465           100             128              64                       relu   \n",
       "547           100             256              64                       relu   \n",
       "439           100             128              32                       relu   \n",
       "548           100             256              64                       relu   \n",
       "\n",
       "    output_activation_functions  batch_size       AUC  \n",
       "519                     softmax          16  0.864237  \n",
       "465                     softmax          16  0.863706  \n",
       "547                     softmax          32  0.862844  \n",
       "439                     softmax          32  0.862162  \n",
       "548                     softmax          64  0.860906  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(\"AUC\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model with the best parameters on train+validation and evaluating on the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word2vec_dim                       100\n",
       "fst_layer_size                     256\n",
       "snd_layer_size                      32\n",
       "hidden_activation_function        relu\n",
       "output_activation_functions    softmax\n",
       "batch_size                          16\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = results_df.sort_values(\"AUC\", ascending=False, ignore_index=True).iloc[0][:-1]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim, fst_layer_size, snd_layer_size, hidden_activation_function, output_activation_function, batch_size = best_params\n",
    "X = dim_to_X_dict[dim]\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(fst_layer_size, activation=hidden_activation_function, input_shape=(dim,)))\n",
    "model.add(layers.Dense(snd_layer_size, activation=hidden_activation_function))\n",
    "model.add(layers.Dense(3, activation=output_activation_function))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"AUC\"])\n",
    "ind = np.concatenate((ind_train, ind_valid))\n",
    "model.fit(X[ind], y[ind], \n",
    "          epochs=20, \n",
    "          batch_size=batch_size,\n",
    "          verbose=0)\n",
    "\n",
    "_, test_AUC = model.evaluate(X[ind_test], y[ind_test], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.8507624864578247\n"
     ]
    }
   ],
   "source": [
    "print(\"Test AUC:\", test_AUC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
